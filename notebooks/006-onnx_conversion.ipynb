{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "697bfba2",
   "metadata": {},
   "source": [
    "## Converting all the PyTorch Models to ONNX\n",
    "\n",
    "ONNX (Open Neural Network Exchange) is an open standard and format for representing machine learning models, allowing interoperability between different AI frameworks like PyTorch and TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43aa1c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cu126\n",
      "True\n",
      "12.6\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9e9472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))  # Go up from notebooks to project root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e4414",
   "metadata": {},
   "source": [
    "### converting LeNet64 to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a033255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ..\\ONNX\\lenet64.onnx\n"
     ]
    }
   ],
   "source": [
    "from utils.model_utils import convert_state_dict_to_onnx\n",
    "from architecture.LeNet64 import Model\n",
    "\n",
    "model = Model()\n",
    "convert_state_dict_to_onnx(\n",
    "    model = model,\n",
    "    state_dict_path = \"../models/LeNet/LeNet64_state_dict.pth\",\n",
    "    output_path = \"../ONNX/lenet64.onnx\",\n",
    "    input_shape = (1, 3, 64, 64)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389ccd7e",
   "metadata": {},
   "source": [
    "### Converting ResNet18 to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97b0036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load pretrained model\n",
    "model_0 = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Freeze all layers except the final FC layer\n",
    "for name, param in model_0.named_parameters():\n",
    "    # Only keep FC trainable\n",
    "    param.requires_grad = (\"fc\" in name)\n",
    "\n",
    "# Replace FC for your number of classes\n",
    "model_0.fc = nn.Linear(model_0.fc.in_features, 3)  # example: 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e24ceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ..\\ONNX\\resnet18.onnx\n"
     ]
    }
   ],
   "source": [
    "convert_state_dict_to_onnx(\n",
    "    model = model_0,\n",
    "    state_dict_path = \"../models/ResNet/ResNet16_state_dict.pth\",\n",
    "    output_path = \"../ONNX/resnet18.onnx\",\n",
    "    input_shape = (1, 3, 224, 224)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939f5613",
   "metadata": {},
   "source": [
    "### Converting TinyVGG to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0be062f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ..\\ONNX\\tinyvgg.onnx\n"
     ]
    }
   ],
   "source": [
    "from architecture.VGG16 import VGG16Lite\n",
    "from utils.model_utils import convert_state_dict_to_onnx\n",
    "\n",
    "state_dict_path2 = Path(\"../models/TinyVGG/new.pth\")\n",
    "state_dict2 = torch.load(state_dict_path2, map_location = device)\n",
    "\n",
    "\n",
    "model3 = VGG16Lite(3,10,3)\n",
    "\n",
    "convert_state_dict_to_onnx(\n",
    "    model = model3,\n",
    "    state_dict_path = \"../models/TinyVGG/new.pth\",\n",
    "    output_path = \"../ONNX/tinyvgg.onnx\",\n",
    "    input_shape = (1, 3, 224, 224)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
